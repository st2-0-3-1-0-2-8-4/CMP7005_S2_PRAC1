{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st2-0-3-1-0-2-8-4/CMP7005_S2_PRAC1/blob/main/st20310284_CMP7005_S2_PRAC1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **st20310284 CMP7005 PRAC1.ipynb**"
      ],
      "metadata": {
        "id": "F6SDf-ahJe4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Import the necessary Libraries:**"
      ],
      "metadata": {
        "id": "AMg1whQmbmau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "EJI3R_ae3dcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the Pandas dataframe:**"
      ],
      "metadata": {
        "id": "09eavbBab9yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "url = \"https://raw.githubusercontent.com/st2-0-3-1-0-2-8-4/CMP7005_S2_PRAC1/refs/heads/main/combined_output.csv\"\n",
        "df = pd.read_csv(url,index_col=0,parse_dates=[0])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gODTwEvY57tn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "4f7a131e-f4cd-4f7b-b41e-73c3d0a731e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5f88428bb754>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the CSV file into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/st2-0-3-1-0-2-8-4/CMP7005_S2_PRAC1/refs/heads/main/combined_output.csv?token=GHSAT0AAAAAADC6OHGDKZSTIAQ3LKRGQWFI2AUVEEA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "7qwAh9tqWUnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df[['year', 'month', 'day']])"
      ],
      "metadata": {
        "id": "UKvPhSTcoPY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "WMuM1oN7cR7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "vYkUTw6sBzGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shows columns in list format\n",
        "df.columns"
      ],
      "metadata": {
        "id": "fwEkPMGNVFWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "B7U8eh7NcqOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Total Number of stations in the dataset**"
      ],
      "metadata": {
        "id": "i8lCrRfYa6mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stations = df['station'].value_counts()\n",
        "print(f'Total number of stations in the dataset : {len(stations)}')\n",
        "stations"
      ],
      "metadata": {
        "id": "d4ML0W8QXevv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Look at the missing values**"
      ],
      "metadata": {
        "id": "FtJwe0j8fX0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "def missing_values_table(df):\n",
        "        # Total missing values\n",
        "        mis_val = df.isnull().sum()\n",
        "\n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "\n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        print(mis_val_table)\n",
        "\n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "\n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n",
        "        '% of Total Values', ascending=False)\n",
        "\n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns\n",
        "\n",
        "missing_values= missing_values_table(df)\n",
        "missing_values.style.background_gradient(cmap='Oranges')"
      ],
      "metadata": {
        "id": "ed9eO5AsfWN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating New DataFrame for Air Quality Index**"
      ],
      "metadata": {
        "id": "newooci1tCjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10', 'wd', 'DEWP', 'PRES', 'TEMP', 'RAIN', 'WSPM', 'year', 'day', 'month', 'hour', 'Date', 'station']\n",
        "\n",
        "# Create a new DataFrame with only the selected columns\n",
        "df1 = df[selected_columns]\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "df1.head()\n"
      ],
      "metadata": {
        "id": "tawbggXIrhEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "def missing_values_table(df1):\n",
        "        # Total missing values\n",
        "        mis_val = df1.isnull().sum()\n",
        "\n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df1.isnull().sum() / len(df1)\n",
        "\n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        mis_val_table\n",
        "\n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "\n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n",
        "        '% of Total Values', ascending=False)\n",
        "\n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns\n",
        "\n",
        "missing_values= missing_values_table(df1)\n",
        "missing_values.style.background_gradient(cmap='Oranges')"
      ],
      "metadata": {
        "id": "7p6y6Zh0tb7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imputing missing values**"
      ],
      "metadata": {
        "id": "qxnjauwAChAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mean/Median/Mode Imputation**\n",
        "* **Mean:** Replace missing values with the mean of the column.\n",
        "\n",
        "* **Median**: Replace missing values with the median of the column. This is useful if your data has outliers, as the median is less sensitive to them.\n",
        "\n",
        "* **Mode:** Replace missing values with the mode (most frequent value) of the column. This is often used for categorical variables but can be applied to numerical data as well."
      ],
      "metadata": {
        "id": "xtP3Y5YyCJJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "dff= df1.groupby(['year','month','station', 'Date'])[pollutants].mean().reset_index()\n",
        "dff"
      ],
      "metadata": {
        "id": "r89YTslNLO4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['CO']=df1['CO'].fillna((df1['CO'].median()))\n",
        "df1['O3']=df1['O3'].fillna((df1['O3'].median()))\n",
        "df1['NO2']=df1['NO2'].fillna((df1['NO2'].median()))\n",
        "df1['SO2']=df1['SO2'].fillna((df1['SO2'].median()))\n",
        "df1['PM2.5']=df1['PM2.5'].fillna((df1['PM2.5'].median()))\n",
        "df1['PM10']=df1['PM10'].fillna((df1['PM10'].median()))\n",
        "df1['TEMP']=df1['TEMP'].fillna((df1['TEMP'].median()))\n",
        "df1['PRES']=df1['PRES'].fillna((df1['PRES'].median()))\n",
        "df1['DEWP']=df1['DEWP'].fillna((df1['DEWP'].median()))\n",
        "df1['RAIN']=df1['RAIN'].fillna((df1['RAIN'].median()))\n",
        "df1['wd']=df1['wd'].fillna((df1['wd'].mode()))\n",
        "df1['WSPM']=df1['WSPM'].fillna((df1['WSPM'].median()))\n"
      ],
      "metadata": {
        "id": "YhK7DB4LLuCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "va7WqvnNMtIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "def missing_values_table(df1):\n",
        "        # Total missing values\n",
        "        mis_val = df1.isnull().sum()\n",
        "\n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df1.isnull().sum() / len(df1)\n",
        "\n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        mis_val_table\n",
        "\n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "\n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n",
        "        '% of Total Values', ascending=False)\n",
        "\n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns\n",
        "\n",
        "missing_values= missing_values_table(df1)\n",
        "missing_values.style.background_gradient(cmap='Oranges')"
      ],
      "metadata": {
        "id": "oNkbSKH0VBnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe().T"
      ],
      "metadata": {
        "id": "eXxwf05pAL4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Insights from the Summary Statistics:**\n",
        "\n",
        "**Date Range & Trends**\n",
        "The dataset spans from March 1, 2013, to Febraury 28, 2017.\n",
        "The median date (~December 31, 2014) suggests that most data points are centered around 2015-2017.\n",
        "\n",
        "**PM2.5 & PM10 Levels (Air Pollution Indicators)**\n",
        "\n",
        "**PM2.5 Mean:** 78.95 µg/m³ (with a max of 941.00 µg/m³ which indicates an extreme pollution event). Levels above 35 µg/m³ are considered unhealthy and precautions should be taken like wearing a face mask.\n",
        "\n",
        "**PM10 Mean:** 104.82 µg/m³ (with a max of 999.00 that is considered hazardous for human health).\n",
        "\n",
        "High standard deviation (79.69 for PM2.5 and 91.87 for PM10) suggest high air quality variations.\n",
        "\n",
        "**Other Pollutants**\n",
        "\n",
        "**CO (Carbon Monoxide):** Mean 1199.05 is considered potentially dangerous and can harm susceptible individuals (with a max of 10,000 which is considered hazardous).\n",
        "\n",
        "**O3 (Ozone):** Mean 57.28 is considered moderate, max 450.00 that is considered very high and is dangerous to all and a health warning should be considered.\n",
        "\n",
        "**Nitric Oxide (NO2):** Mean 50.00 is considered generally safe but prolonged exposure can affect vulnerable people, max 290.00 is considered concerning for human health.\n",
        "\n",
        "**SO2 (Sulfur Dioxide):** Mean 14.61is considered good air quality, max 500 represents a significant concern.\n",
        "\n",
        "**Final Thoughts:**\n",
        "\n",
        "The data suggests severe air pollution events, with occasional hazardous levels.\n",
        "High variability across pollutants implies that air quality is affected by multiple factors (seasonal changes, industrial activity, and vehicular emissions).\n",
        "\n",
        "Further EDA with time-series analysis can help identify pollution trends and their causes."
      ],
      "metadata": {
        "id": "gxVYf3JROCzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Subsetting columns**\n",
        "Even though a lot of columns have been provided in the dataset, we shall select a few prominent ones. Let's create a new dataframe called pollutants containg the major pollutants responsible for air pollution."
      ],
      "metadata": {
        "id": "V2q9tyIT8vuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']"
      ],
      "metadata": {
        "id": "gklY03xl85Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "id": "r_LlK4ZdN23T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualisation of each pollutants (using daily data)**"
      ],
      "metadata": {
        "id": "-DOhkmtxKGlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.set_index('Date',inplace=True)\n",
        "axes = df1[pollutants].plot(marker='.', alpha=0.5, linestyle='None', figsize=(16, 20), subplots=True)\n",
        "for ax in axes:\n",
        "\n",
        "    ax.set_xlabel('years')\n",
        "    ax.set_ylabel('ug / m3')"
      ],
      "metadata": {
        "id": "MV-tbtQf89Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Monthwise Plot**"
      ],
      "metadata": {
        "id": "R9WEQySTKTtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "df1.reset_index(inplace=True)  # Moves 'Date' from index to a column\n",
        "\n",
        "# Ensure 'Date' column is datetime type\n",
        "df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
        "\n",
        "# Convert pollutant columns to numeric, coercing errors to NaN\n",
        "pollutant_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "for col in pollutant_columns:\n",
        "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values (if needed)\n",
        "#df1 = df1.dropna(subset=pollutant_columns)\n",
        "\n",
        "# Grouping by year and month, and calculating mean for each pollutant\n",
        "df1['Month'] = df1['Date'].dt.to_period('M')\n",
        "df_monthly = df1.groupby('Month')[pollutant_columns].mean()\n",
        "\n",
        "# Create subplots: one for each pollutant\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    subplot_titles=[\"Pollutant Levels by Month\"]\n",
        ")\n",
        "\n",
        "# Adding line plot for each pollutant\n",
        "for pollutant in pollutant_columns:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df_monthly.index.astype(str),  # Convert PeriodIndex to string for x-axis\n",
        "            y=df_monthly[pollutant],\n",
        "            mode='lines+markers',  # You can change to 'lines' or 'markers' depending on the style\n",
        "            name=pollutant\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title=\"Month-wise Pollutant Levels\",\n",
        "    xaxis_title=\"Month\",\n",
        "    yaxis_title=\"Pollutant Concentration (µg/m³)\",\n",
        "    height=600,\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qFmaWpp6Dgqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df1 and pollutants are already defined\n",
        "# Group by Year and Month to calculate the monthly average for each pollutant\n",
        "monthly_avg = df1.groupby(['year', 'month'])[pollutants].mean().reset_index()\n",
        "\n",
        "# Create a Date column from Year and Month\n",
        "monthly_avg['Date'] = pd.to_datetime(monthly_avg[['year', 'month']].assign(DAY=1))\n",
        "\n",
        "# Create subplots for each pollutant\n",
        "fig = make_subplots(rows=len(pollutants), cols=1, subplot_titles=[f'{pollutant} Monthly Average Concentration Over Time' for pollutant in pollutants])\n",
        "\n",
        "# Add traces for each pollutant\n",
        "for i, pollutant in enumerate(pollutants):\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=monthly_avg['Date'],\n",
        "            y=monthly_avg[pollutant],\n",
        "            mode='lines+markers',\n",
        "            name=pollutant,\n",
        "            line=dict(color='blue', width=2),\n",
        "            marker=dict(size=8),\n",
        "            opacity=0.7\n",
        "        ),\n",
        "        row=i+1, col=1\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title_text='Monthly Average Concentrations of Pollutants Over Time',\n",
        "    title_font_size=24,\n",
        "    showlegend=False,\n",
        "    height=300 * len(pollutants),  # Adjust height based on the number of pollutants\n",
        "    width=1000\n",
        ")\n",
        "\n",
        "# Update y-axis labels\n",
        "for i, pollutant in enumerate(pollutants):\n",
        "    fig.update_yaxes(title_text=f'{pollutant} (ug/m3)', row=i+1, col=1)\n",
        "\n",
        "# Update x-axis labels\n",
        "fig.update_xaxes(title_text='Date', row=len(pollutants), col=1)\n",
        "\n",
        "# Rotate x-axis labels\n",
        "fig.update_xaxes(tickangle=45)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cs5gCtiVl4y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_avg"
      ],
      "metadata": {
        "id": "hSpI-gJ641UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Month to calculate the monthly average for each pollutant\n",
        "monthly_avg = df.groupby('month')[pollutants].mean()\n",
        "\n",
        "# Plotting the monthly average for each pollutant\n",
        "fig, axes = plt.subplots(len(pollutants), 1, figsize=(10, 15), sharex=False)\n",
        "\n",
        "# Define month names for x-axis labels\n",
        "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "\n",
        "for i, pollutant in enumerate(pollutants):\n",
        "    ax = axes[i]\n",
        "    ax.plot(month_names, monthly_avg[pollutant], marker='o', linestyle='-', color='blue', alpha=0.7, label='Monthly Average')\n",
        "    ax.set_ylabel(f'{pollutant} (ug/m3)')\n",
        "    ax.set_title(f'{pollutant} Monthly Average Concentration')\n",
        "    ax.legend()\n",
        "    ax.set_xlabel('Month')  # Set x-axis label\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "# Set a common title for the figure\n",
        "fig.suptitle('Monthly Average Concentrations of Pollutants Over Time', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rBCNRxgcuayU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# df1.reset_index(inplace=True)  # Moves 'Date' from index to a column\n",
        "\n",
        "# Ensure 'Date' column is in datetime type\n",
        "df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
        "\n",
        "# Convert pollutant columns to numeric, coercing errors to NaN\n",
        "pollutant_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "for col in pollutant_columns:\n",
        "    df1[col] = pd.to_numeric(df1[col], errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values (if needed)\n",
        "df1 = df1.dropna(subset=pollutant_columns)\n",
        "\n",
        "# Grouping by year, and calculating mean for each pollutant\n",
        "df1['Year'] = df1['Date'].dt.year\n",
        "df_yearly = df1.groupby('Year')[pollutant_columns].mean()\n",
        "\n",
        "# Create subplots: one for each pollutant\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    subplot_titles=[\"Yearly Pollutant Levels\"]\n",
        ")\n",
        "\n",
        "# Adding line plot for each pollutant\n",
        "for pollutant in pollutant_columns:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df_yearly.index.astype(str),  # Convert Year to string for x-axis\n",
        "            y=df_yearly[pollutant],\n",
        "            mode='lines+markers',  # You can change to 'lines' or 'markers' depending on the style\n",
        "            name=pollutant\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(\n",
        "    title=\"Yearly Pollutant Levels\",\n",
        "    xaxis_title=\"Year\",\n",
        "    yaxis_title=\"Pollutant Concentration (µg/m³)\",\n",
        "    height=600,\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "r96grax2K9S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Most Dominant Pollutants:**"
      ],
      "metadata": {
        "id": "Hrs-s3pFALot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "pol=df1[pollutants].mean()\n",
        "pollutants_df=pol.to_frame().reset_index()\n",
        "pollutants_df.columns=['Pollutant','Level']\n",
        "pollutants_df"
      ],
      "metadata": {
        "id": "6gVTFsW7AfbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,6))\n",
        "\n",
        "labels = pollutants_df['Pollutant']\n",
        "explode = [0, 0.1, 0, 0, 0, 0]  # Exploding the first slice (CO)\n",
        "\n",
        "plt.title('Dominant Pollutants in Beijing')\n",
        "wedges, texts, autotexts = plt.pie(\n",
        "    pollutants_df['Level'],\n",
        "    explode=explode,\n",
        "    autopct='%1.1f%%',\n",
        "    shadow=True,\n",
        "    startangle=0\n",
        ")\n",
        "\n",
        "plt.axis('equal')  # Ensures the pie chart is drawn as a circle\n",
        "\n",
        "# Adding legend\n",
        "plt.legend(\n",
        "    wedges,\n",
        "    labels,\n",
        "    title=\"Pollutants\",\n",
        "    loc=\"center\",\n",
        "    bbox_to_anchor=(1, 0, 0.5, 1)\n",
        ")\n",
        "\n",
        "# Setting the properties of the percentage texts\n",
        "plt.setp(autotexts, size=14, weight='bold')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jmy7WNVHCbCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dominant Pollutant stationwise**"
      ],
      "metadata": {
        "id": "nt8yLkcKPQ2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "\n",
        "# Group data by 'State' and calculate the mean of each pollutant\n",
        "statewise_pollution_means = df1.groupby('station')[pollutants].mean()\n",
        "\n",
        "# Find the dominant pollutant in each state\n",
        "dominant_pollutant_by_state = statewise_pollution_means.idxmax(axis=1)\n",
        "\n",
        "# Convert the result to a DataFrame for better readability\n",
        "dominant_pollutant_df = dominant_pollutant_by_state.reset_index()\n",
        "dominant_pollutant_df.columns = ['Station', 'Dominant Pollutant']\n",
        "\n",
        "# Display the results\n",
        "dominant_pollutant_df\n"
      ],
      "metadata": {
        "id": "iF-0gaYtHUoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation between the different Pollutants**"
      ],
      "metadata": {
        "id": "_EvTvH94OVLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter the DataFrame to include only numeric columns\n",
        "# This assumes you want to include only the pollutants columns\n",
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "numeric_pollutants_df = df1[pollutants]\n",
        "\n",
        "# Convert data to numeric (this will handle any non-numeric values)\n",
        "numeric_pollutants_df = numeric_pollutants_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows with any NaN values (if any)\n",
        "numeric_pollutants_df = numeric_pollutants_df\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_pollutants_df.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, center=0)\n",
        "plt.title('Correlation Heatmap of Pollutants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-zHEyyv84ymb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The above shows a correlation between CO and all other Pollutants**"
      ],
      "metadata": {
        "id": "MsTJXnnrNHA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dt4ujl2RKnhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pollutants_df.corr()"
      ],
      "metadata": {
        "id": "rRkjXQfmCan3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation between the different Pollutants and Weather Conditions**"
      ],
      "metadata": {
        "id": "OrnVA-72KeGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter the DataFrame to include only numeric columns\n",
        "# This assumes you want to include only the weather columns\n",
        "weather_and_pollutants = ['DEWP','PRES','TEMP', 'RAIN', 'WSPM', 'CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "numeric_weather_df = df1[weather_and_pollutants]\n",
        "\n",
        "# Convert data to numeric (this will handle any non-numeric values)\n",
        "numeric_weather_df = numeric_weather_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows with any NaN values (if any)\n",
        "numeric_weather_df = numeric_weather_df\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = numeric_weather_df.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1, center=0)\n",
        "plt.title('Correlation Heatmap of Weather')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b399gnkhoQYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The above shows a correlation between O3 and Temperature**"
      ],
      "metadata": {
        "id": "Rk86Pge8MT1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming df1 is your DataFrame and it contains the pollutant columns\n",
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "\n",
        "# Filter the DataFrame to include only the pollutant columns\n",
        "pollutants_df = df1[pollutants]\n",
        "\n",
        "# Ensure all columns are numeric\n",
        "pollutants_df = pollutants_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values\n",
        "pollutants_df = pollutants_df.dropna()\n",
        "\n",
        "# Create scatter plots between each pair of pollutants\n",
        "# Use pairplot from seaborn to plot all pairwise scatter plots\n",
        "sns.pairplot(pollutants_df, diag_kind='kde', plot_kws={'alpha':0.5})\n",
        "plt.suptitle('Pairwise Scatter Plots of Pollutants', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TcFHSo8JB2dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Top 2 polluted Stations (based on Pollutants)**\n",
        "\n",
        "Let's now look at the Beijing stations which contribute to maximum pollution. We shall output the top 2 stations in each pollutant category by mean concentration of the pollutant over the years."
      ],
      "metadata": {
        "id": "ep700zRlqzJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoZfZDaxUBeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_polluted_station(pollutants):\n",
        "    x1 = df[[pollutants,'station']].groupby([\"station\"]).mean().sort_values(by=pollutants,ascending=False).reset_index()\n",
        "    x1[pollutants] = round(x1[pollutants],2)\n",
        "    return x1[:10].style.background_gradient(cmap='OrRd')"
      ],
      "metadata": {
        "id": "c9HzVVbjrUJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display_html\n",
        "\n",
        "def display_side_by_side(*args):\n",
        "    # Convert each DataFrame's Styler object to HTML and join them together\n",
        "    html_str = ''\n",
        "    for df in args:\n",
        "        html_str += df._repr_html_()  # Use _repr_html_ to get the HTML representation\n",
        "    display_html(html_str.replace('table', 'table style=\"display:inline;margin-right:20px;\"'), raw=True)\n",
        "\n",
        "# Example usage with your top pollutant DataFrames\n",
        "co = max_polluted_station('CO')\n",
        "o3 = max_polluted_station('O3')\n",
        "no2 = max_polluted_station('NO2')\n",
        "so2 = max_polluted_station('SO2')\n",
        "pm2_5 = max_polluted_station('PM2.5')\n",
        "pm10 = max_polluted_station('PM10')\n",
        "\n",
        "# Display the DataFrames side by side\n",
        "display_side_by_side(co, o3, no2, so2, pm2_5, pm10)\n"
      ],
      "metadata": {
        "id": "44tPAsRi0xvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your DataFrame with pollutant data\n",
        "pollutant_columns = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "# Step 1: Group by station and calculate mean pollutant concentrations\n",
        "mean_pollutant_by_station = df.groupby('station')[pollutant_columns].mean()\n",
        "\n",
        "# Step 2: Find the top 2 stations for each pollutant\n",
        "top_stations = {}\n",
        "for pollutant in pollutant_columns:\n",
        "    top_stations[pollutant] = mean_pollutant_by_station[pollutant].sort_values(ascending=False).head(10)\n",
        "\n",
        "# Step 3: Plotting\n",
        "fig, axes = plt.subplots(len(pollutant_columns), 1, figsize=(10, 20))\n",
        "\n",
        "for i, pollutant in enumerate(pollutant_columns):\n",
        "    axes[i].barh(top_stations[pollutant].index, top_stations[pollutant].values, color='skyblue')\n",
        "    axes[i].set_title(f'Top 2 Station by {pollutant}')\n",
        "    axes[i].set_xlabel(f'{pollutant}')\n",
        "    axes[i].invert_yaxis()  # Highest values on top\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3l5-UpFa-G5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pollutant columns\n",
        "pollutants = ['CO', 'O3', 'NO2', 'SO2', 'PM2.5', 'PM10']\n",
        "\n",
        "# Calculate the average levels of pollutants for each station\n",
        "station_pollution = df1.groupby('station')[pollutants].mean()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the average pollutants for each station\n",
        "station_pollution.plot(kind=\"bar\",\n",
        "                 figsize=(10,10),\n",
        "                 stacked=True)\n",
        "plt.title('Average Pollutant Levels Across Station')\n",
        "plt.xlabel('Station')\n",
        "plt.ylabel('Pollutant Level')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KW42TllKkD4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}